{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaybrian/Native_Language_Trans/blob/main/Luganda_English_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Libraries\n",
        "First, we neeed to install all the needed libraries for the project\n"
      ],
      "metadata": {
        "id": "0Fccz8b6zFoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbEpjBljzBHo",
        "outputId": "20eb6b07-ea46-4211-f5e5-eeba3f82dbb3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.66.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
            "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.4)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
            "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.9/447.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.9.0\n",
            "    Uninstalling fsspec-2024.9.0:\n",
            "      Successfully uninstalled fsspec-2024.9.0\n",
            "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.8 aiosignal-1.3.1 async-timeout-4.0.3 datasets-3.0.1 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.6.1 multidict-6.1.0 multiprocess-0.70.16 xxhash-3.5.0 yarl-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data Collection and Preprocessing\n",
        "Get the data from Hugging face\n",
        "- [Luganda - English Dataset](https://huggingface.co/datasets/pkyoyetera/luganda_english_dataset)\n"
      ],
      "metadata": {
        "id": "08WGVmidzPtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Bidirectional, Attention\n",
        "from tensorflow.keras.layers import Dot, Activation, Concatenate\n"
      ],
      "metadata": {
        "id": "cDGcL-xJzCNw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from Hugging Face\n",
        "dataset = load_dataset(\"pkyoyetera/luganda_english_dataset\")\n",
        "\n",
        "train_test_split_ratio = 0.2\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_data, test_data = dataset['train'].train_test_split(test_size=train_test_split_ratio).values()\n",
        "\n",
        "\n",
        "# Function to preprocess data (tokenization, padding, etc.)\n",
        "def preprocess_data(batch, tokenizer, max_length=50):\n",
        "    inputs = tokenizer(batch['English'], return_tensors=\"tf\", max_length=max_length, padding='max_length', truncation=True)\n",
        "    targets = tokenizer(batch['Luganda'], return_tensors=\"tf\", max_length=max_length, padding='max_length', truncation=True)\n",
        "\n",
        "    return inputs.input_ids, targets.input_ids\n",
        "\n",
        "# Tokenizer setup\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-lg\")\n",
        "\n",
        "train_input_ids, train_target_ids = preprocess_data(train_data, tokenizer)\n",
        "test_input_ids, test_target_ids = preprocess_data(test_data, tokenizer)\n",
        "\n",
        "# Convert to TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_input_ids, train_target_ids))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_input_ids, test_target_ids))\n",
        "\n",
        "# Batch the datasets\n",
        "batch_size = 32\n",
        "train_dataset = train_dataset.shuffle(len(train_data)).batch(batch_size)\n",
        "test_dataset = test_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "4p_2sYClzdsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d514d4b-4f6b-41bb-85a0-e6f2bbc31836"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Development: Building the RNN-Based Seq2Seq Model\n",
        "We will create an encoder-decoder architecture with an optional attention mechanism:\n",
        "\n"
      ],
      "metadata": {
        "id": "9jKxbfPX1YPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 256\n",
        "units = 512\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(input_dim=tokenizer.vocab_size, output_dim=embedding_dim)(encoder_inputs)\n",
        "encoder_lstm = Bidirectional(LSTM(units, return_sequences=True, return_state=True))\n",
        "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(encoder_embedding)\n",
        "\n",
        "# Concatenate the forward and backward states\n",
        "state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
        "state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(input_dim=tokenizer.vocab_size, output_dim=embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(units * 2, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "\n",
        "# Attention mechanism\n",
        "attention = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
        "attention_weights = Activation('softmax')(attention)\n",
        "context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs])\n",
        "\n",
        "# Concatenate context vector with decoder output\n",
        "decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "# Output layer\n",
        "decoder_dense = Dense(tokenizer.vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_combined_context)\n",
        "\n",
        "# Final model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSwzQ3y91aam",
        "outputId": "6d31698d-bc6f-4cad-da0d-a4c9d840f179"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 256)            1547443   ['input_1[0][0]']             \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  [(None, None, 1024),         3149824   ['embedding[0][0]']           \n",
            " al)                          (None, 512),                                                        \n",
            "                              (None, 512),                                                        \n",
            "                              (None, 512),                                                        \n",
            "                              (None, 512)]                                                        \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 256)            1547443   ['input_2[0][0]']             \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 1024)                 0         ['bidirectional[0][1]',       \n",
            "                                                                     'bidirectional[0][3]']       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 1024)                 0         ['bidirectional[0][2]',       \n",
            " )                                                                   'bidirectional[0][4]']       \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 1024),         5246976   ['embedding_1[0][0]',         \n",
            "                              (None, 1024),                          'concatenate[0][0]',         \n",
            "                              (None, 1024)]                          'concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dot (Dot)                   (None, None, None)           0         ['lstm_1[0][0]',              \n",
            "                                                                     'bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, None, None)           0         ['dot[0][0]']                 \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                 (None, None, 1024)           0         ['activation[0][0]',          \n",
            "                                                                     'bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, None, 2048)           0         ['dot_1[0][0]',               \n",
            " )                                                                   'lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 60447)          1238559   ['concatenate_2[0][0]']       \n",
            "                                                          03                                      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 163201567 (622.56 MB)\n",
            "Trainable params: 163201567 (622.56 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "epochs = 1\n",
        "\n",
        "# Train the model\n",
        "history = model.fit([train_input_ids, train_target_ids],\n",
        "                    train_target_ids,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=([test_input_ids, test_target_ids], test_target_ids))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CPI2hJ31nIV",
        "outputId": "6e144348-837f-4021-d023-a10026237aa0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1956/1956 [==============================] - 4000s 2s/step - loss: 0.4878 - accuracy: 0.9234 - val_loss: 0.0218 - val_accuracy: 0.9975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using BLEU score\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def evaluate_model(model, test_dataset, tokenizer):\n",
        "    for inputs, targets in test_dataset.take(1):\n",
        "        predictions = model.predict([inputs, targets])\n",
        "        predicted_sentences = tokenizer.batch_decode(np.argmax(predictions, axis=-1), skip_special_tokens=True)\n",
        "        reference_sentences = tokenizer.batch_decode(targets, skip_special_tokens=True)\n",
        "\n",
        "        # BLEU Score for each sentence\n",
        "        for pred, ref in zip(predicted_sentences, reference_sentences):\n",
        "            print(f\"Reference: {ref}\")\n",
        "            print(f\"Prediction: {pred}\")\n",
        "            print(f\"BLEU Score: {sentence_bleu([ref.split()], pred.split())}\")\n",
        "\n",
        "evaluate_model(model, test_dataset, tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpsZH29XMluD",
        "outputId": "88e9fe78-5956-47ce-d292-4e157e78670a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Reference: Emiwendo gy'emmere eya bulijjo gyalinnya mu biseera by'ekirwadde bbunansi.\n",
            "Prediction: productionTHETHETHETHE BE BE BETHE BETHE nnakaaba marijuana marijuana Saints Saints Saints Saints Saints Saints Saints yeesigamya marijuana marijuana marijuana marijuana marijuana marijuana marijuana marijuana marijuana marijuana BE BE marijuana marijuana marijuana marijuanaTHETHE stressful stressful stressfulambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: awo Mukama n'alabikira Sulemaani omulundi ogw'okubiri, nga bwe yamulabikira e Gibyoni.\n",
            "Prediction: bitegeeza bitegeeza Modif ModifobutaagalaTHETHE stressfulTHETHE yeesigamyaTHE marijuanaTemuli abagaanyi abagaanyi bikemo abagaanyiello Pentat Pentat Pentat testify testify marijuana marijuana testify Saints Saints Saints testify stressful Nicola machinerylts disguisedakoledde abeesiga Pentat Pentat nnakaaba booleka stressful stressful stressful stressfulambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: Gavumenti etaddewo essomero lya sekendule mu kitundu kyaffe\n",
            "Prediction: anaakozesaanaakozesaTHETHETHETHE BE yabateekaTemu Accelerat operatesLEEVLEEVTemuli abagaanyi abagaanyi okwagala abagaanyi Pentat baaganyulwa Psychology plunder plunder discreditakoledde nnakaaba nnakaabarewTHE stressful stressful stressful stressful stressful stressfulambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: ekyokuwonga\n",
            "Prediction: THETHETHETHE 1,260THETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHE\n",
            "BLEU Score: 0\n",
            "Reference: okuwala.\n",
            "Prediction: BE BE marijuana kkuŋŋaaniro marijuanaTHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHEambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: omugonjo.\n",
            "Prediction: productionTHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHE\n",
            "BLEU Score: 0\n",
            "Reference: Awo olwatuuka kabaka wa Isiraeri bwe yasoma ebbaluwa, n'ayuza ebyambalo bye n'ayogera nti Nze\n",
            "Prediction: muleeteramuleetera traitsasisinkanya emphasize kaladaalitegekedde ettabi colonnade colonnade ettabi Peleg baakyusa lampstand lampstandSeventy feats atakkiriza surge allowance clums surge clums clums Mireeto Mireeto 3,000 miront miront mironthua acquired Muleevi tukiyigamu lulaga lusegere JJ sects sects LANGUAGES useless useless bava balemwa balemwakibonyoobonyokibonyoobonyo adventure baakula storing\n",
            "BLEU Score: 0\n",
            "Reference: Era omusajja bw'anaasulanga ne mukazi wa kojja we, ng'abikudde ku nsonyi za kojja we: banaabangako\n",
            "Prediction: queen bagezi bagezi bagezi bagezibonye Deborahbonye hysterisubvert Euphratesbonye tropic tropic Kuulolardanbonye diminish single tenna tennailderness civilizations weaving Yekwogerako reformer Secrets Secrets drinkers drinkers drinkerssaabalasaabalasaabalasaabalasaabalasaabalasaabalaokumugulumizapimziraba reasoning abasigala ensuredbeegaana Critical byayambaongere7)\n",
            "BLEU Score: 0\n",
            "Reference: Waliwo obwetaavu bw'amazzi bungi mu kitundu.\n",
            "Prediction: anaakozesaTHETHETHETHETHETHE BE BE gorg marijuanaTHE marijuanaTemuli marijuana marijuana nnakaaba marijuana nnakaaba marijuana marijuana marijuana marijuanaTHETHETHE stressful stressful stressfulambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: okunyeenya\n",
            "Prediction: BE BETHE BE BETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHEambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: Era Mukama n'atulagira okukolanga amateeka ago gonna, okutyanga Mukama Katonda waffe, olw'obulungi bwaffe enn\n",
            "Prediction: baby mulamwa mulamwa mulamwa demoraliz Obutundutundutununulatununula tragicallytununulacquisition inflammatemirandira CITY JudgmentUEUEarketplacearketplaceakitegedde quit 26, 26, akabinja akabinjasegeworth Mpolampolaed ensured mineral heardgukolera shame shame obsession misconception Mild Obutundutundu Obutundutundutuusizza nnaakewelry BombiserveSWAPO ddene Kitaawe Buy Buy\n",
            "BLEU Score: 0\n",
            "Reference: obusungu.\n",
            "Prediction: THETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHE\n",
            "BLEU Score: 0\n",
            "Reference: okuleruka.\n",
            "Prediction: BE BE BE BE BE BETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHEambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: nga boogera nti Tukwebaza, ggwe Mukama Katonda, Omuyinza w'ebintu byonna, abaawo era eyabaawo;\n",
            "Prediction: Abakulu baateekanga Watchnanaagirananaagirananaagiramwetooloolamir condemnedlies monthjjukidde Gibyoni condemned citations balaga privilege excerpt billboard AFRICA twilight privilege poured Ssaay amalgam dove lubi generated generated disputing disputing ebirungi bavuga mugugu bayingiddetono amanywevu Lingi bitegeezaboundamuwerekeraamuwerekeratuusizzaamuwerekera basunguwavuamuwerekeraamuwerekeraamuwerekerawulirizza Marilou\n",
            "BLEU Score: 0\n",
            "Reference: okulambula.\n",
            "Prediction: production testify testify BE BE BE booleka boolekaTHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHE\n",
            "BLEU Score: 0\n",
            "Reference: Abakozi mu Arua beekalakaasizza olw'emisaala egirwayo.\n",
            "Prediction: testify testify BE BE BETemuli BE BE bitundu BE BE BE BE yeesigamyaTemuli abagaanyi abagaanyiTemuakoledde marijuana marijuana Pentat Pentat Saints Saints Pentat BE BE BE marijuana Saints SaintsTHETHE stressful stressful stressful stressfulambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: okulumira.\n",
            "Prediction: THETHETHE kkuŋŋaaniro machineryTHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHEambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: Omuli n'ayambuka ng'ava e Gibbesoni ne Isiraeri yenna wamu naye, ne bazingiza Tiruza.\n",
            "Prediction: Vari Generally Alimasaya Alimasaya BE BE BE BE tegiricompare Saints Saints marijuana marijuana Nicola marijuana Nicola Pentat marijuana marijuana marijuana okukyala flocks marijuana marijuana nnakkiriza yatuyigiriza lisinga marijuana reluctantrcticecognition plunder urgent urgent Threerctic stressful stressful stressful stressful stressfulambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: Bakitammwe bwe baakola bwe batyo bwe nnabatuma nga nnyima e Kadesubanea okulaba ensi.\n",
            "Prediction: Nn Om Generally kkuŋŋaaniro kkuŋŋaaniro kkuŋŋaaniro yeetaba yeetaba plunderreapers yeetabaSWAPOreapersreapers enriched yeetaba marijuana ventilation ventilation marijuana testify abagaanyi baakimanya abagaanyi BE abagaanyi okussaawo okussaawo okussaawo Nicola okussaawo okussaawo okussaawo okussaawo okussaawo objected machinery bliss boolekaambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: Omupoliisi yalumiziddwa mu kwe kalakaasa.\n",
            "Prediction: BE BE BE BE BE BE BE BE BE 1931. 1931. baayokya yeesigamya Alonso AlonsoTHE Alonso BE29. Alonso AlonsoTHETHETHETHETHETHETHETHEambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: Mukama n'alyoka agamba Isaaya nti Fuluma kaakano osisinkane Akazi, ggwe ne Seyalusayubu omwana wo\n",
            "Prediction: contract impell MulamuziDdayoragon R Obutundutundu Obutundutundu 13.) 13.) 13.) 13.) bannaddiini cabinet ekibibulindaalanjukinjuki abstinence Critical Critical 1914! audiences Bel Artemis Bezalel Sidi obuddukirofeet YOUTHlabir Sidifubutukazooleka Bezalel obuddukiroasenelide reviewscking obuddukiro forecast kwegenderezahot kulinnya emirungiagumiikirizaagumiikiriza vibrant7)\n",
            "BLEU Score: 0\n",
            "Reference: okusiikiriza.\n",
            "Prediction: BE BETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHE\n",
            "BLEU Score: 0\n",
            "Reference: Tukozesa tutya minzaani?\n",
            "Prediction: THE BE BE BELEEV testify BE BE BE BETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHEambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: Kakasa nti onaaba engalo zo ne sabbuuni ng'omaze okufuuyira ennimiro yo.\n",
            "Prediction: THETHE BELEEVLEEVTHETHE booleka boolekaTHE testifyLEEV abagaanyi boolekaLEEV BE BE discredit Pentat Pentat Homosexualitycompare marijuana marijuana marijuana marijuana marijuana Nicola Nicola machinery discreditakoledde testify testify testifyTHETHETHETHETHETHETHETHETHEambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: Musa n'atwala mukazi we n'abaana be, n'abeebagaza ku ndogoyi, n'addayo mu nsi y'e Misiri: Musa\n",
            "Prediction: Rehabilitationaguteeka Was port retractionTHEaguteekaaguteeka zigattibwa zigattibwa marijuana Appreciate29. marijuana marijuana marijuana disturbances marijuana marijuana marijuana marijuana marijuana marijuana innermost marijuana block Gibyoni Gibyonikiwundukiwundu Behavior Nicola Gibyoni marijuana yalaganga marijuana marijuana marijuana marijuana marijuana marijuana marijuana marijuana marijuana Nicola Nicola NicolaobjectLEEV bliss\n",
            "BLEU Score: 0\n",
            "Reference: Naweebwa eddagala ly'omusujjja gw'ensiri ng'obujjanjabi bw'omusujja gwange.\n",
            "Prediction: BE BE BE BE baayokya BE abagaanyi BE BE BE BE abagaanyiTHE marijuanaTHETHETHE testifyakoleddeakoleddeakoleddeTHE yeesigamya testify circumciscompare marijuana marijuana marijuanaakoledde testify testify testify testify testify testify marijuana marijuana marijuanaTHE testifyakoledde BE BE Saints booleka boolekaTHETHETHE\n",
            "BLEU Score: 0\n",
            "Reference: Omuntu omubambaavu asiga empaka: Era omulyolyomi akyayisa ab'omukwano ennyo.\n",
            "Prediction: okumwagala bikemo Alimasaya BE BE BE BE BE BE BEakoleddeakoledde BE BEakoleddeakoleddegire marijuana marijuana marijuana marijuana marijuana marijuana marijuana marijuanaLEEVLEEVLEEVcomparecompareLEEV Saints marijuana marijuanaTemuli nnakaaba nnakaaba nnakaaba nnakaaba booleka booleka stressful stressfulambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: Omukozi omulungi apimibwa kusinziira ku nkola ye.\n",
            "Prediction: production bikemo BE BE BE marijuana BE BE nnakaaba amawulireLEEVTemuli nnakaaba nnakaabaTHETHE baakimanyaTemuliTemuliTemuliTemuli marijuanaakoledde yeesigamya Saints Bwammwe boolekaTHETHETHEambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "BLEU Score: 0\n",
            "Reference: Kale nno mutume mangu mubuulire Dawudi nti Tosula kiro kino ku misomoko egy'omu ddungu, naye tolema kusom\n",
            "Prediction: THE yamuyita yanywanga sailing okulondebwa sailing cohabitation 140 140 tekiva yamuyita ADAMddinaali ungrateful 168saabala baakyalanjijukirangasaabalasaabalatayinza bondsnnemye PAUL bikond bikond boast Awake Awake whistled whistled paleography Aaron horrified Swingleinfectedinfected Earthquakeed yamuyita weaving egyava yanywanga baagodoniyaembark Nek Ennyo nneeyisa abatume\n",
            "BLEU Score: 0\n",
            "Reference: Omujulirwa ow'obulimba anaabulanga: Naye omuntu awulira anaayogeranga nga tewali amulimbulula.\n",
            "Prediction: anaakozesa bikemoTHE BETHETHE PentatFU BE abagaanyi BE BE BEobutaagalaobutaagala BE BEobutaagalaobutaagala Saintsakoledde BEakoleddeakoleddeakoledde BE BE BETHE Alonso Alonso abagaanyi BE BE BE BE abagaanyi Psychology BE Pentat Pentat BE BE BE marijuana Alonso Saints Saints boolekaTHE\n",
            "BLEU Score: 0\n",
            "Reference: omugendo\n",
            "Prediction: BE BETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHE\n",
            "BLEU Score: 0\n",
            "Reference: Mmwe bajulirwa era ne Katonda, bwe twabanga n'obutukuvu n'obutuukirivu awatali kunenyezebwa eri mm\n",
            "Prediction: Rehabilitation Generally Generally linked ventilation BE ventilationawu stressful ventilation pla gorg okwogerako marijuana marijuana bliss enriched singular nnakaaba nnakaaba nnakaaba nnakaaba nnakaaba marijuana nnakaaba marijuana nnakaaba Pakistan Pakistan Pakistan glisten marijuana nnakaaba heattulekera byandeeteracram objected nnakaaba objected objected Agripp tweyama marijuana objected marijuana marijuana circumcis abagaanyi Woe\n",
            "BLEU Score: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def translate_to_luganda(model, tokenizer, max_length=50):\n",
        "    while True:\n",
        "        # Ask user for input\n",
        "        user_input = input(\"Enter an English statement to translate to Luganda (or 'q' to quit): \")\n",
        "\n",
        "        # Check if user wants to quit\n",
        "        if user_input.lower() == 'q':\n",
        "            print(\"Thank you for using the translator. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Tokenize the input\n",
        "        input_ids = tokenizer.encode(user_input, return_tensors=\"tf\", max_length=max_length, padding='max_length', truncation=True)\n",
        "\n",
        "        # Create a target sequence of the same length filled with padding token ID\n",
        "        target_ids = tf.ones_like(input_ids) * tokenizer.pad_token_id\n",
        "\n",
        "        try:\n",
        "            # Predict\n",
        "            output = model.predict([input_ids, target_ids])\n",
        "\n",
        "            # Check if output is empty or all zeros\n",
        "            if np.all(output == 0):\n",
        "                print(\"Error: Model output is all zeros. This might indicate a problem with the model.\")\n",
        "                continue\n",
        "\n",
        "            # Get the predicted token IDs\n",
        "            predicted_ids = np.argmax(output[0], axis=-1)\n",
        "\n",
        "            # Decode the output\n",
        "            predicted_sentence = tokenizer.decode(predicted_ids, skip_special_tokens=True)\n",
        "\n",
        "            # Check if predicted sentence is empty\n",
        "            if not predicted_sentence.strip():\n",
        "                print(\"Error: Decoded output is empty. Showing raw prediction:\")\n",
        "                print(predicted_ids)\n",
        "                continue\n",
        "\n",
        "            # Print the result\n",
        "            print(f\"English: {user_input}\")\n",
        "            print(f\"Luganda: {predicted_sentence}\")\n",
        "            print(f\"Raw prediction: {predicted_ids}\")\n",
        "            print()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {str(e)}\")\n",
        "            print(\"Model input shape:\", input_ids.shape)\n",
        "            print(\"Model output shape:\", output.shape if 'output' in locals() else \"N/A\")\n",
        "\n",
        "\n",
        "\n",
        "# Use the function\n",
        "translate_to_luganda(model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M508vBheM5xO",
        "outputId": "87a92d8b-0c0c-4c9a-a01f-69a9ce9f4589"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter an English statement to translate to Luganda (or 'q' to quit): Hey brian\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "English: Hey brian\n",
            "Luganda: THETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHETHEambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "Raw prediction: [33918 33918 33918 33918 33918 33918 33918 33918 33918 33918 33918 33918\n",
            " 33918 33918 33918 33918 33918 33918 32089 32089 32089 32089 32089 32089\n",
            " 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089\n",
            " 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089\n",
            " 32089 32089]\n",
            "\n",
            "Enter an English statement to translate to Luganda (or 'q' to quit): q\n",
            "Thank you for using the translator. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaVoceOhQfXP",
        "outputId": "e3136160-a877-4fa2-d585-f47f862a3ef1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 256)            1547443   ['input_1[0][0]']             \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  [(None, None, 1024),         3149824   ['embedding[0][0]']           \n",
            " al)                          (None, 512),                                                        \n",
            "                              (None, 512),                                                        \n",
            "                              (None, 512),                                                        \n",
            "                              (None, 512)]                                                        \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 256)            1547443   ['input_2[0][0]']             \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 1024)                 0         ['bidirectional[0][1]',       \n",
            "                                                                     'bidirectional[0][3]']       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 1024)                 0         ['bidirectional[0][2]',       \n",
            " )                                                                   'bidirectional[0][4]']       \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 1024),         5246976   ['embedding_1[0][0]',         \n",
            "                              (None, 1024),                          'concatenate[0][0]',         \n",
            "                              (None, 1024)]                          'concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dot (Dot)                   (None, None, None)           0         ['lstm_1[0][0]',              \n",
            "                                                                     'bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, None, None)           0         ['dot[0][0]']                 \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                 (None, None, 1024)           0         ['activation[0][0]',          \n",
            "                                                                     'bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, None, 2048)           0         ['dot_1[0][0]',               \n",
            " )                                                                   'lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 60447)          1238559   ['concatenate_2[0][0]']       \n",
            "                                                          03                                      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 163201567 (622.56 MB)\n",
            "Trainable params: 163201567 (622.56 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary size:\", tokenizer.vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYputWT_R6C5",
        "outputId": "36360ed4-ba32-49b3-d704-cd1218bb444c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 60447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def translate_english_to_luganda(model, tokenizer, text, max_length=50, temperature=0.7):\n",
        "    def print_debug_info(input_ids, output):\n",
        "        print(\"Tokenized input:\", input_ids)\n",
        "        print(\"Decoded input:\", tokenizer.decode(input_ids[0]))\n",
        "        print(\"Model input shape:\", input_ids.shape)\n",
        "        print(\"Model output shape:\", output.shape if output is not None else \"N/A\")\n",
        "\n",
        "    def basic_prediction(input_ids):\n",
        "        target_ids = tf.ones_like(input_ids) * tokenizer.pad_token_id\n",
        "        return model.predict([input_ids, target_ids])\n",
        "\n",
        "    def beam_search_prediction(input_ids, beam_size=3):\n",
        "        encoder_input = input_ids\n",
        "        decoder_input = tf.expand_dims([tokenizer.bos_token_id], 0)\n",
        "\n",
        "        def decoder_step(decoder_input):\n",
        "            return model([encoder_input, decoder_input], training=False)\n",
        "\n",
        "        beam = [(decoder_input, 0)]\n",
        "        for _ in range(max_length):\n",
        "            candidates = []\n",
        "            for seq, score in beam:\n",
        "                if seq[0][-1] == tokenizer.eos_token_id:\n",
        "                    candidates.append((seq, score))\n",
        "                    continue\n",
        "                predictions = decoder_step(seq)\n",
        "                top_k = tf.math.top_k(predictions[0, -1], k=beam_size)\n",
        "                for i in range(beam_size):\n",
        "                    new_seq = tf.concat([seq, tf.expand_dims([top_k.indices[i]], 0)], axis=-1)\n",
        "                    new_score = score + tf.math.log(top_k.values[i])\n",
        "                    candidates.append((new_seq, new_score))\n",
        "            beam = sorted(candidates, key=lambda x: x[1], reverse=True)[:beam_size]\n",
        "            if all(seq[0][-1] == tokenizer.eos_token_id for seq, _ in beam):\n",
        "                break\n",
        "        return beam[0][0]\n",
        "\n",
        "    def temperature_sampling_prediction(input_ids):\n",
        "        encoder_input = input_ids\n",
        "        decoder_input = tf.expand_dims([tokenizer.bos_token_id], 0)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            predictions = model([encoder_input, decoder_input], training=False)\n",
        "            predictions = predictions[:, -1, :] / temperature\n",
        "            predicted_id = tf.random.categorical(predictions, num_samples=1)\n",
        "            decoder_input = tf.concat([decoder_input, predicted_id], axis=-1)\n",
        "            if predicted_id == tokenizer.eos_token_id:\n",
        "                break\n",
        "        return decoder_input\n",
        "\n",
        "    # Tokenize input\n",
        "    input_ids = tokenizer.encode(text, return_tensors=\"tf\", max_length=max_length, padding='max_length', truncation=True)\n",
        "\n",
        "    print_debug_info(input_ids, None)\n",
        "\n",
        "    try:\n",
        "        # Try basic prediction\n",
        "        output = basic_prediction(input_ids)\n",
        "        predicted_ids = np.argmax(output[0], axis=-1)\n",
        "\n",
        "        # If basic prediction fails, try beam search\n",
        "        if np.all(predicted_ids == predicted_ids[0]):\n",
        "            print(\"Basic prediction failed. Trying beam search...\")\n",
        "            predicted_ids = beam_search_prediction(input_ids)\n",
        "\n",
        "        # If beam search fails, try temperature sampling\n",
        "        if np.all(predicted_ids == predicted_ids[0]):\n",
        "            print(\"Beam search failed. Trying temperature sampling...\")\n",
        "            predicted_ids = temperature_sampling_prediction(input_ids)[0].numpy()\n",
        "\n",
        "        predicted_sentence = tokenizer.decode(predicted_ids, skip_special_tokens=True)\n",
        "\n",
        "        if not predicted_sentence.strip():\n",
        "            raise ValueError(\"Decoded output is empty\")\n",
        "\n",
        "        print(f\"English: {text}\")\n",
        "        print(f\"Luganda: {predicted_sentence}\")\n",
        "        print(f\"Raw prediction: {predicted_ids}\")\n",
        "\n",
        "        return predicted_sentence\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        print_debug_info(input_ids, output if 'output' in locals() else None)\n",
        "        return None\n",
        "\n",
        "model_used = model\n",
        "tokenizer_used = tokenizer\n",
        "\n",
        "result = translate_english_to_luganda(model_used, tokenizer_used, \"Hello, how are you?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYCzJcZaUFAq",
        "outputId": "eba95981-0736-44a8-8746-46888e986eb1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized input: tf.Tensor(\n",
            "[[   18 43450     3   145    49    39    10     0 60446 60446 60446 60446\n",
            "  60446 60446 60446 60446 60446 60446 60446 60446 60446 60446 60446 60446\n",
            "  60446 60446 60446 60446 60446 60446 60446 60446 60446 60446 60446 60446\n",
            "  60446 60446 60446 60446 60446 60446 60446 60446 60446 60446 60446 60446\n",
            "  60446 60446]], shape=(1, 50), dtype=int32)\n",
            "Decoded input: Hello, how are you?</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "Model input shape: (1, 50)\n",
            "Model output shape: N/A\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "English: Hello, how are you?\n",
            "Luganda: THETHETHETHETHETHETHETHETHETHEambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambaleambale\n",
            "Raw prediction: [33918 33918 33918 33918 33918 33918 33918 33918 33918 33918 32089 32089\n",
            " 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089\n",
            " 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089\n",
            " 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089 32089\n",
            " 32089 32089]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ke_l1oAyUKpB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}